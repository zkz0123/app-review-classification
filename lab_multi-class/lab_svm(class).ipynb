{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "889a6b9e-8e08-44fd-8257-6fce40caf525",
   "metadata": {},
   "source": [
    "# **Classification of app reviews for requirements engineering using deep learning models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383bb831-c726-4152-981c-60f88ccfea66",
   "metadata": {},
   "source": [
    "## **Data Loading and Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89538384-5398-40d5-8c16-4d49468e8983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datasets import Dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c9b421b-3f73-49bc-b4cc-df5c0799fefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = 'dataset/balanced/gpt_balanced_8000.xlsx'\n",
    "dataframe = pd.read_excel(file_path)\n",
    "\n",
    "# data clean\n",
    "dataframe['review'] = dataframe['review'].fillna('')\n",
    "\n",
    "dataset = Dataset.from_pandas(dataframe)\n",
    "texts = dataset['review']\n",
    "labels = dataset['new_label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69a3afe7-9075-44ca-8b77-99c3707debe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.2, shuffle=True, stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db0769cc-468d-43cd-83cc-612298c4c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling (TF-IDF + MaxAbsScaler)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_tfidf)\n",
    "X_test_scaled = scaler.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883b48ef-c23c-497c-b7e1-7312155480ec",
   "metadata": {},
   "source": [
    "## **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3117b4dc-16d2-4e48-8ec5-3de0ad13df9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 0.5, 1],\n",
    "    'tol': [1e-5, 1e-4, 1e-3],\n",
    "    'max_iter': [5000, 10000, 20000],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# param_grid = {\n",
    "#     'C': [0.1],\n",
    "#     'tol': [1e-5],\n",
    "#     'max_iter': [5000],\n",
    "# }\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    LinearSVC(dual=False, random_state=42), \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58191625-d11b-410a-8101-0f0d1c9720ad",
   "metadata": {},
   "source": [
    "## **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f944587-bd17-47b5-8609-4c4b433563df",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "start_time = time.time()\n",
    "\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8160a52-f52f-49d1-bb80-1b254a807ce3",
   "metadata": {},
   "source": [
    "## **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5082b10c-bf39-42f0-a5d8-185c26676b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff17dc41-4598-4bb1-8ba3-1089fa0f20cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "report_dict = classification_report(y_test, y_pred, target_names=['bug report', 'feature request', 'rating', 'user experience'], output_dict=True)\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "report_df = report_df.round(4)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", report_df)\n",
    "\n",
    "macro_f1 = report_dict[\"macro avg\"][\"f1-score\"]\n",
    "print(f\"\\nMacro F1 Score: {macro_f1:.4f}\")\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "# Confusion Matrix Visualization\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "#             xticklabels=['bug report', 'feature request', 'rating', 'user experience'], \n",
    "#             yticklabels=['bug report', 'feature request', 'rating', 'user experience'])\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.xlabel('Predicted Labels')\n",
    "# plt.ylabel('True Labels')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f313faa6-2db4-43ce-82d5-b5138409e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classification report\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "report_path = os.path.join('models/svm', f\"classification_report_{timestamp}.csv\")\n",
    "report_df.to_csv(report_path, float_format='%.4f')\n",
    "print(f\"Classification report saved to {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00876ba-71ec-4214-97e5-b389f9e9a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# os.makedirs('models/svm', exist_ok=True)\n",
    "# model_filename = f'models/svm/best_model_{timestamp}.pkl'\n",
    "\n",
    "# joblib.dump(best_model, model_filename)\n",
    "# print(f\"Model saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4e730f-0763-4bd1-baa1-0365a9bc1bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
